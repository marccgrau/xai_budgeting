{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the Loughran & McDonald Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MasterDictionary class\n",
    "class MasterDictionary:\n",
    "    def __init__(self, cols, _stopwords):\n",
    "        for ptr, col in enumerate(cols):\n",
    "            if col == '':\n",
    "                cols[ptr] = '0'\n",
    "        self.word = cols[0].upper()\n",
    "        self.sequence_number = int(cols[1])\n",
    "        self.word_count = int(cols[2])\n",
    "        self.word_proportion = float(cols[3])\n",
    "        self.average_proportion = float(cols[4])\n",
    "        self.std_dev_prop = float(cols[5])\n",
    "        self.doc_count = int(cols[6])\n",
    "        self.negative = int(cols[7]) > 0\n",
    "        self.positive = int(cols[8]) > 0\n",
    "        self.uncertainty = int(cols[9]) > 0\n",
    "        self.litigious = int(cols[10]) > 0\n",
    "        self.strong_modal = int(cols[11]) > 0\n",
    "        self.weak_modal = int(cols[12]) > 0\n",
    "        self.constraining = int(cols[13]) > 0\n",
    "        self.syllables = int(cols[14])\n",
    "        self.source = cols[15]\n",
    "        self.stopword = self.word in _stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MasterDictionary function\n",
    "def load_masterdictionary(file_path, print_flag=False, _stopwords=set()):\n",
    "    _master_dictionary = {}\n",
    "    _sentiment_categories = ['negative', 'positive', 'uncertainty', 'litigious', 'strong_modal', 'weak_modal', 'constraining']\n",
    "    _sentiment_dictionaries = {sentiment: dict() for sentiment in _sentiment_categories}\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        _md_header = f.readline()  # Consume header line\n",
    "        for line in f:\n",
    "            cols = line.strip().split(',')\n",
    "            if cols[0]:  # Ensure there's a word\n",
    "                _master_dictionary[cols[0]] = MasterDictionary(cols, _stopwords)\n",
    "                for sentiment in _sentiment_categories:\n",
    "                    if getattr(_master_dictionary[cols[0]], sentiment, False):\n",
    "                        _sentiment_dictionaries[sentiment][cols[0].upper()] = True\n",
    "\n",
    "    if print_flag:\n",
    "        print(f\"Master Dictionary loaded with {len(_master_dictionary)} words.\")\n",
    "\n",
    "    return _master_dictionary, _sentiment_dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary is regularly updated here: https://sraf.nd.edu/loughranmcdonald-master-dictionary/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Dictionary loaded with 86553 words.\n"
     ]
    }
   ],
   "source": [
    "# Load the Loughran-McDonald dictionary\n",
    "md_path = 'C:/Users/domin/Documents/GitHub/xai_budgeting/001_data/003_experiment/002_justifications/Loughran-McDonald_MasterDictionary_1993-2023.csv'\n",
    "master_dictionary, sentiment_dictionaries = load_masterdictionary(md_path, print_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Process Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(file_path, sentiment_dictionaries):\n",
    "    results = []\n",
    "\n",
    "    # Attempt to read the file and analyze each line, ignoring the first row\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        next(file)  # Skip the first line\n",
    "        for line in file:\n",
    "            # Strip the newline character from each line\n",
    "            text = line.strip()\n",
    "            \n",
    "            # Skip empty lines\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            # Initialize dictionary to count occurrences of each sentiment category\n",
    "            counts = {sentiment: 0 for sentiment in sentiment_dictionaries.keys()}\n",
    "\n",
    "            # Count sentiment words in the text\n",
    "            for word in text.upper().split():\n",
    "                for sentiment, dictionary in sentiment_dictionaries.items():\n",
    "                    if word in dictionary:\n",
    "                        counts[sentiment] += 1\n",
    "\n",
    "            # Add the text snippet and counts to the results list\n",
    "            results.append({\n",
    "                'Text': text[:50],  # Include the first 50 characters of the text for reference\n",
    "                **counts  # Unpack the sentiment counts into the dictionary\n",
    "            })\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Save as .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save initial submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis results saved to C:/Users/domin/Documents/GitHub/xai_budgeting/001_data/003_experiment/002_justifications/loughran_initial_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path of the file to process\n",
    "text_path = 'C:/Users/domin/Documents/GitHub/xai_budgeting/001_data/003_experiment/002_justifications/initial_submission.txt'\n",
    "\n",
    "# Process the specified text file\n",
    "df_results = process_text_file(text_path, sentiment_dictionaries)\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "output_csv_path = 'C:/Users/domin/Documents/GitHub/xai_budgeting/001_data/003_experiment/002_justifications/loughran_initial_results.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_results.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Sentiment analysis results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save AI resubmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis results saved to C:/Users/domin/Documents/GitHub/xai_budgeting/001_data/003_experiment/002_justifications/loughran_airesubmissions_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path of the file to process\n",
    "text_path = 'C:/Users/domin/Documents/GitHub/xai_budgeting/001_data/003_experiment/002_justifications/ai_resubmissions.txt'\n",
    "\n",
    "# Process the specified text file\n",
    "df_results = process_text_file(text_path, sentiment_dictionaries)\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "output_csv_path = 'C:/Users/domin/Documents/GitHub/xai_budgeting/001_data/003_experiment/002_justifications/loughran_airesubmissions_results.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_results.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Sentiment analysis results saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
